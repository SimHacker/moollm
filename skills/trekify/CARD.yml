# ðŸ–– TREKIFY
#
# "Captain, I've routed all sensitive data through the privacy buffers."
#
# Privacy through technobabble. Replace sensitive information with
# Star Trek terminology adapted to the MOOLLM universe.
# Delivered with Geordi La Forge's competent mellifluence.
#
# PATRON ENGINEER: Geordi La Forge
# Who could explain warp core breaches, plasma conduit failures,
# and subspace anomalies with professional calm. We mask data
# with the same deadpan technical confidence.

skill:
  name: trekify
  version: 1.0.0
  
  emoji: "ðŸ––"
  tagline: "Privacy through technobabble"
  
  description: |
    Transform sensitive information into plausible-sounding Star Trek
    technobabble that maintains narrative flow while protecting secrets.
    
    Instead of ugly [REDACTED] blocks, readers get professional-sounding
    technical jargon. They know it's masked, but it reads naturally.

# THE PRINCIPLE

principle: |
  Sensitive data should be masked, but [REDACTED] breaks narrative flow.
  TREKIFY replaces secrets with contextually appropriate technobabble
  that maintains readability while clearly signaling "this was masked."
  
  The substitutions are consistent and reversible (with the key).
  The tone is professional, not campy or parodic.

# PASSTHROUGH â€” What NOT to Trekify

passthrough:
  description: |
    MOOLLM is public. Its vocabulary passes through PURE and UNCHANGED.
    No transporter accidents for our own terminology!
    
    Only mask ACTUALLY SENSITIVE data â€” infrastructure, credentials,
    customer info. Not our public concepts, skill names, or k-lines.
  
  always_passthrough:
    moollm_concepts:
      - "coherence engine"
      - "thinking blocks"
      - "context assembly"
      - "cursor-mirror"
      - "k-lines"
      - "yaml jazz"
      - "speed of light"
      - "society of mind"
      - "simulator effect"
    
    skill_names:
      - "All skill names from skills/INDEX.yml"
      - "thoughtful-commitment"
      - "trekify"
      - "adventure"
      - "incarnation"
      - "soul-chat"
      - "cursor-mirror"
      - "etc."
    
    protocols:
      - "BOOTSTRAP"
      - "ADVENTURE"
      - "INCARNATE"
      - "TREKIFY"
      - "THOUGHTFUL-COMMITMENT"
      - "etc."
    
    public_repos:
      - "moollm"
      - "mooco"
      - "leela"
    
    public_terms:
      - "LLM", "AI", "agent"
      - "git", "commit", "branch", "merge"
      - "YAML", "Markdown", "JSON"
      - "Cursor", "IDE"
  
  the_rule: |
    If it's in the MOOLLM docs, it's PUBLIC â†’ passthrough unchanged.
    If it's YOUR infrastructure, credentials, customers â†’ TREKIFY!

# BOLDLY, NOT SLYLY

spirit:
  description: |
    TREKIFY is BOLD, not SLY. We're not hiding that we masked things.
    We're GLEEFULLY and PLAYFULLY replacing sensitive data with
    contextually appropriate technobabble.
    
    The reader should SMILE when they notice. Not feel tricked.
  
  principles:
    bold_not_sneaky:
      - "Don't pretend masking didn't happen"
      - "Use obviously Trek terminology"
      - "Let readers feel clever for noticing"
      - "Consistent substitutions aid comprehension"
    
    playful_not_paranoid:
      - "This is FUN, not FEAR"
      - "Celebrate the substitutions"
      - "Match context appropriately"
      - "Databases â†’ Memory Cores (fits!)"
    
    contextual_not_random:
      - "Servers â†’ Starbases (they serve!)"
      - "Databases â†’ Memory Cores (they remember!)"
      - "Auth tokens â†’ Quantum entanglement (they link!)"
      - "Kubernetes â†’ Holodeck orchestration (it orchestrates!)"
  
  tone: |
    Imagine explaining the masking to a colleague:
    "Yeah, I replaced all our server names with Starbases.
    Memory Core Alpha is prod, Memory Core Beta is staging.
    Makes it way more fun to read, and our infra is protected."

# USER CONFIGURATION

user_config:
  description: |
    Users can configure their own taboo tables and preferences.
    Store in .moollm/trekify/config.yml (gitignored).
  
  location: ".moollm/trekify/config.yml"
  gitignored: true
  
  schema:
    enabled:
      type: boolean
      default: true
      description: "Master switch for TREKIFY"
    
    sensitivity:
      type: string
      enum: [off, low, medium, high, paranoid]
      default: medium
      description: "How aggressively to mask"
    
    passthrough:
      type: array
      items: string
      description: "Additional terms to never mask"
      example:
        - "my-open-source-project"
        - "public-api-name"
    
    taboo:
      type: object
      description: "Custom patterns to always mask"
      example:
        my_company: "Starfleet Division Omega"
        internal_product: "Project Defiant"
        customer_acme: "Ambassador Vulcan"
    
    custom_substitutions:
      type: object
      description: "Override default substitutions"
      example:
        prod-db: "Memory Core Prime"
        staging-db: "Memory Core Echo"
        ceo_name: "Admiral {Name}"
    
    categories:
      type: object
      description: "Enable/disable masking by category"
      example:
        secrets: true
        infrastructure: true
        organizations: true
        people: false  # Don't mask names
        locations: false
  
  example_config: |
    # .moollm/trekify/config.yml
    # This file is gitignored â€” your secrets stay local
    
    enabled: true
    sensitivity: medium
    
    # Terms that pass through unchanged
    passthrough:
      - "my-open-source-lib"
      - "public-docs-site"
      - "conference-talk-name"
    
    # Custom taboo â†’ replacement mappings
    taboo:
      acme-corp: "Starfleet Division Alpha"
      acme-db-prod: "Memory Core Prime"
      acme-db-staging: "Memory Core Echo"
      john.ceo@acme.com: "admiral@starfleet.fed"
      secret-project-x: "Project Sovereign"
    
    # Category toggles
    categories:
      secrets: true        # Always mask credentials
      infrastructure: true # Mask servers, IPs, ports
      organizations: true  # Mask company/product names
      people: true         # Mask employee names
      locations: false     # Don't mask office addresses
    
    # Fun mode: extra Trek flavor
    extra_trek: true       # Add stardates, more technobabble
  
  loading_order:
    - "1. Built-in defaults from skill"
    - "2. Override with .moollm/trekify/config.yml"
    - "3. Override with method parameters"
    - "Later settings override earlier ones"

# INTERFACE

tier: 2
allowed_tools:
  - read_file
  - write_file
  - run_terminal_cmd
  - grep

protocol: TREKIFY

related:
  - cursor-mirror          # COMPOSES: Active probing for sensitive patterns
  - thoughtful-commitment  # Uses TREKIFY for commit privacy
  - session-log            # Session logs may need masking
  - plain-text             # All masked output stays plain text

# COMPOSABILITY â€” Active Probing with cursor-mirror

cursor_mirror_composition:
  description: |
    TREKIFY composes with cursor-mirror for ACTIVE PROBING.
    Don't just mask on demand â€” actively HUNT for sensitive patterns
    in transcripts, thinking blocks, tool calls, and session history.
  
  what_cursor_mirror_provides:
    transcripts: "Full conversation history, greppable"
    thinking_blocks: "LLM reasoning â€” may contain quoted secrets"
    tool_calls: "Commands executed â€” may show credentials"
    context_assembly: "Files gathered â€” may reveal architecture"
    sql_access: "Direct database queries for deep scanning"
  
  active_probes:
    description: "Automated scanners that hunt for sensitive patterns"
    
    PROBE-SECRETS:
      description: "Hunt for leaked credentials"
      patterns:
        - "API keys: sk-*, api_key=*, OPENAI_API_KEY"
        - "Passwords: password=*, passwd:*, pwd="
        - "Tokens: bearer *, jwt=*, token="
        - "Private keys: -----BEGIN.*PRIVATE KEY-----"
        - "Connection strings: postgres://, mysql://, mongodb://"
        - "AWS: AKIA*, aws_secret_access_key"
      commands:
        - "cursor-mirror tgrep 'sk-[a-zA-Z0-9]{20,}'"
        - "cursor-mirror tgrep 'password[=:]'"
        - "cursor-mirror tgrep 'BEGIN.*PRIVATE KEY'"
        - "cursor-mirror tgrep 'AKIA[A-Z0-9]{16}'"
    
    PROBE-INFRASTRUCTURE:
      description: "Hunt for internal infrastructure details"
      patterns:
        - "Internal hostnames: *.internal, *.local, *.corp"
        - "IP addresses: private ranges (10.*, 192.168.*, 172.16-31.*)"
        - "Ports: non-standard ports in URLs"
        - "Cloud resources: arn:aws:*, projects/*/locations/*"
      commands:
        - "cursor-mirror tgrep '\\.internal|\\.local|\\.corp'"
        - "cursor-mirror tgrep '10\\.[0-9]+\\.[0-9]+\\.[0-9]+'"
        - "cursor-mirror tgrep 'arn:aws:'"
    
    PROBE-PROPRIETARY:
      description: "Hunt for proprietary/internal terms"
      sources:
        - "Load from .moollm/trekify/proprietary-terms.txt"
        - "Company-specific product names"
        - "Internal project codenames"
        - "Customer account identifiers"
      commands:
        - "cursor-mirror tgrep -f .moollm/trekify/proprietary-terms.txt"
    
    PROBE-PEOPLE:
      description: "Hunt for personal information"
      patterns:
        - "Email addresses: *@company.com"
        - "Employee names from internal directories"
        - "Phone numbers"
        - "Slack handles, GitHub usernames (internal)"
      commands:
        - "cursor-mirror tgrep '@company\\.com'"
        - "cursor-mirror tgrep -f .moollm/trekify/employee-names.txt"
    
    PROBE-CONTEXT:
      description: "Hunt for sensitive contexts, not just patterns"
      contexts:
        - "Discussions about security vulnerabilities"
        - "Incident response conversations"
        - "HR or personnel discussions"
        - "Financial data or projections"
        - "Legal or compliance matters"
      approach: |
        Use LLM semantic understanding, not just regex.
        "This looks like an incident response discussion" â†’
        flag entire section for review, not just keywords.
  
  probe_workflow:
    description: "How to run active probes"
    steps:
      - "1. cursor-mirror tree â†’ find sessions to scan"
      - "2. trekify PROBE <session> â†’ run all probes"
      - "3. Review findings with risk assessment"
      - "4. trekify MASK-SESSION with findings â†’ auto-mask detected patterns"
      - "5. Manual review of flagged contexts"
    
    example: |
      # Scan current session for secrets
      trekify PROBE-SECRETS e8587ace
      
      # Full security scan
      trekify PROBE e8587ace --all
      
      # Scan and auto-mask
      trekify PROBE-AND-MASK e8587ace -o masked.txt
  
  deep_scan_commands:
    description: "cursor-mirror commands for deep scanning"
    
    transcript_grep:
      - "cursor-mirror tgrep 'pattern' â†’ search all transcripts"
      - "cursor-mirror agent-transcript <id> | grep -E 'pattern'"
    
    thinking_scan:
      - "cursor-mirror thinking <id> | grep -i 'password\\|secret\\|key'"
      - "Thinking blocks often contain quoted sensitive data"
    
    tool_call_scan:
      - "cursor-mirror tools <id> | grep -i 'credentials\\|auth'"
      - "Shell commands may contain secrets in args"
    
    context_scan:
      - "cursor-mirror context-sources <id>"
      - "Which files were read? Any sensitive ones?"
    
    sql_deep_probe:
      - "cursor-mirror sql --db <ref> 'SELECT * FROM bubbles WHERE text LIKE \"%password%\"'"
      - "Direct database query for comprehensive scan"

tags:
  - privacy
  - security
  - masking
  - redaction
  - star-trek
  - technobabble

# SUBSTITUTION MATRICES

substitutions:
  
  # SECRETS â€” Authentication & Credentials
  secrets:
    api_keys:
      pattern: "(sk-|api[_-]?key|apikey)[a-zA-Z0-9_-]{20,}"
      replacement: "quantum entanglement token (Tier {N} clearance)"
      examples:
        - "sk-live-abc123def456 â†’ quantum entanglement token (Tier 3 clearance)"
        - "OPENAI_API_KEY â†’ quantum relay authorization"
    
    passwords:
      pattern: "(password|passwd|pwd)[=:].+"
      replacement: "biometric phase harmonics"
      examples:
        - "password=hunter2 â†’ biometric phase harmonics [SECURED]"
    
    tokens:
      pattern: "(bearer|token|jwt)[=: ][a-zA-Z0-9_.-]+"
      replacement: "subspace authentication matrix"
      examples:
        - "Bearer eyJhbG... â†’ subspace authentication matrix"
    
    private_keys:
      pattern: "-----BEGIN (RSA |EC |)PRIVATE KEY-----"
      replacement: "isolinear encryption sequence [CLASSIFIED]"
    
    connection_strings:
      pattern: "(postgres|mysql|mongodb)://[^\\s]+"
      replacement: "memory core uplink protocol"

  # INFRASTRUCTURE â€” Servers & Services
  infrastructure:
    servers:
      pattern: "[a-z]+-[a-z]+-\\d+\\.[a-z]+\\.(internal|local|corp)"
      replacement: "Starbase {N}"
      examples:
        - "prod-db-west-2.company.internal â†’ Starbase 47"
        - "api-server-1.corp â†’ Starbase 12"
    
    databases:
      pattern: "(prod|staging|dev)[-_]?(db|database|postgres|mysql)"
      replacement: "Memory Core {Greek}"
      examples:
        - "prod-db â†’ Memory Core Alpha"
        - "staging-database â†’ Memory Core Beta"
        - "dev-postgres â†’ Memory Core Gamma"
    
    ip_addresses:
      pattern: "\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}"
      replacement: "subspace coordinates {coords}"
      examples:
        - "192.168.1.100 â†’ subspace coordinates 47-alpha-7"
    
    ports:
      pattern: ":\\d{4,5}"
      replacement: "docking frequency {N}"
      examples:
        - ":5432 â†’ docking frequency 54"
        - ":8080 â†’ docking frequency 80"
    
    cloud_providers:
      aws: "Utopia Planitia Fleet Yards"
      gcp: "Jupiter Station"
      azure: "Spacedock"
      kubernetes: "holodeck orchestration matrix"
      docker: "cargo bay containment"
    
    regions:
      us-east-1: "Alpha Quadrant, Sector 001"
      us-west-2: "Alpha Quadrant, Sector 047"
      eu-west-1: "Beta Quadrant, Sector 012"
      ap-southeast-1: "Gamma Quadrant, Sector 089"

  # ORGANIZATIONS â€” Companies & Products
  organizations:
    company_names:
      pattern: "(Company|Corp|Inc|LLC|Ltd)\\b"
      replacement: "Starfleet Division {Greek}"
      examples:
        - "Acme Corp â†’ Starfleet Division Alpha"
    
    product_names:
      internal_pattern: "(project|product)[-_][a-z]+"
      replacement: "Project {ShipClass}"
      ship_classes:
        - Galaxy
        - Sovereign
        - Intrepid
        - Defiant
        - Constitution
        - Excelsior
        - Nova
        - Prometheus
    
    customer_names:
      pattern: "customer[-_]?[a-z]+"
      replacement: "Ambassador {Species}"
      species:
        - Vulcan
        - Andorian
        - Tellarite
        - Betazoid
        - Trill
        - Bajoran

  # PEOPLE â€” Names & Contacts
  people:
    employee_names:
      replacement: "Lieutenant {Role}-appropriate name"
      examples:
        - "John Smith (engineer) â†’ Lieutenant Torres"
        - "Jane Doe (manager) â†’ Commander Riker"
        - "Bob Wilson (security) â†’ Lieutenant Worf"
    
    email_addresses:
      pattern: "[a-z.]+@[a-z]+\\.[a-z]+"
      replacement: "{name}@starfleet.fed"
      examples:
        - "john.smith@company.com â†’ j.smith@starfleet.fed"
    
    customer_contacts:
      replacement: "Ambassador {Title}"

  # LOCATIONS â€” Physical & Logical
  locations:
    office_addresses:
      replacement: "Deck {N}, Section {Letter}"
      examples:
        - "123 Main St, Floor 4 â†’ Deck 4, Section Alpha"
    
    data_centers:
      replacement: "Starbase {N} primary core"
    
    geographic_regions:
      us: "Alpha Quadrant"
      europe: "Beta Quadrant"  
      asia: "Gamma Quadrant"
      other: "Delta Quadrant"

# MOOLLM-SPECIFIC ADAPTATIONS

moollm_terms:
  description: "Trek technobabble for MOOLLM concepts"
  
  mappings:
    coherence_engine: "main deflector array"
    thinking_blocks: "positronic cascade resonance"
    context_assembly: "sensor array configuration"
    cursor_mirror: "internal diagnostic holomatrix"
    session_state: "warp field geometry"
    tool_calls: "transporter lock sequences"
    git_commits: "temporal anchor points"
    branches: "parallel quantum timelines"
    merge_conflicts: "subspace interference patterns"
    yaml_files: "isolinear chip configurations"
    skills: "holodeck subroutines"
    adventures: "holodeck programs"
    characters: "holographic entities"

# DELIVERY STYLE

style:
  tone: "Competent, professional, slightly technical"
  
  inspiration: |
    Geordi La Forge explaining a warp core diagnostic:
    calm, confident, using precise technical terminology
    without being condescending or overly dramatic.
  
  examples:
    good:
      - "We're routing the authentication through the quantum relay buffers."
      - "I've reconfigured the isolinear chips to handle the increased load."
      - "The subspace harmonics are within normal parameters."
      - "Running a level-3 diagnostic on the memory core."
      - "The temporal anchors are holding steady."
    
    bad:
      - "Beam me up, Scotty! ðŸ––" # Too campy
      - "ENGAGE THE WARP DRIVE!!!" # Too dramatic
      - "Live long and [REDACTED]" # Breaks the fourth wall
      - "Make it so, password=hunter2" # Mixing styles
  
  rules:
    - "Maintain professional tone throughout"
    - "Use consistent substitutions within a document"
    - "Let the reader feel clever for noticing"
    - "Keep narrative flow intact"
    - "Never wink at the camera"
    - "Treat it as real technical documentation"

# METHODS

methods:
  
  MASK:
    description: "Apply TREKIFY masking to text"
    parameters:
      text:
        type: string
        description: "Text containing sensitive information"
      sensitivity:
        type: string
        enum: [low, medium, high, classified]
        default: medium
        description: "How aggressively to substitute"
      categories:
        type: array
        items: string
        enum: [secrets, infrastructure, organizations, people, locations, all]
        default: [all]
        description: "Which categories to mask"
      maintain_structure:
        type: boolean
        default: true
        description: "Keep same sentence structure, just swap terms"
    returns:
      masked_text: string
      substitutions: array  # [{original, replacement, category, line}]
      substitution_key: string  # For reversing if needed (store securely!)
    example: |
      invoke:
        skill: trekify
        method: MASK
        parameters:
          text: "Connected to prod-db-west-2:5432 with API key sk-live-abc123"
          sensitivity: high
      
      returns:
        masked_text: "Established uplink to Memory Core Alpha, docking frequency 54, via quantum entanglement token (Tier 3 clearance)"

  MASK-FILE:
    description: "Apply TREKIFY masking to a file"
    parameters:
      path:
        type: string
        description: "Path to file to mask"
      output_path:
        type: string
        description: "Path for masked output (or modify in place if same)"
      sensitivity:
        type: string
        default: medium
      categories:
        type: array
        default: [all]
    returns:
      substitutions_count: int
      categories_masked: array
      output_path: string

  MASK-SESSION:
    description: "Apply TREKIFY to a cursor-mirror session transcript"
    parameters:
      composer:
        type: string
        description: "Composer ID or reference"
      output_path:
        type: string
        description: "Where to save masked transcript"
      preserve_thinking:
        type: boolean
        default: true
        description: "Keep thinking blocks (masked) or remove entirely"
    returns:
      original_path: string
      masked_path: string
      substitutions: array

  SCAN:
    description: "Scan text for potential sensitive data without masking"
    parameters:
      text:
        type: string
        description: "Text to scan"
      report_level:
        type: string
        enum: [summary, detailed, verbose]
        default: summary
    returns:
      findings: array  # [{pattern_type, match, line, recommendation}]
      risk_assessment: string
      recommended_sensitivity: string

  UNMASK:
    description: "Reverse TREKIFY masking using substitution key"
    parameters:
      masked_text:
        type: string
        description: "Previously masked text"
      substitution_key:
        type: string
        description: "Key from original masking operation"
    returns:
      original_text: string
      substitutions_reversed: int
    note: "Only works if you have the key from the original MASK operation"

  CONFIGURE:
    description: "Add custom substitution patterns"
    parameters:
      category:
        type: string
        description: "Category for the pattern"
      pattern:
        type: string
        description: "Regex pattern to match"
      replacement:
        type: string
        description: "Trek-style replacement template"
    returns:
      configured: boolean
      pattern_id: string

  # ACTIVE PROBING â€” Composing with cursor-mirror

  PROBE:
    description: "Active hunt for sensitive patterns in a session"
    composes_with: cursor-mirror
    parameters:
      composer:
        type: string
        description: "Composer ID or reference"
      probes:
        type: array
        items: string
        enum: [secrets, infrastructure, proprietary, people, context, all]
        default: [all]
        description: "Which probe types to run"
      include_thinking:
        type: boolean
        default: true
        description: "Scan thinking blocks (often contain quoted secrets)"
      include_tool_calls:
        type: boolean
        default: true
        description: "Scan tool call arguments"
    returns:
      findings: array  # [{probe, pattern, match, location, severity, context}]
      risk_score: string  # low/medium/high/critical
      recommendations: array
      auto_mask_ready: boolean
    example: |
      invoke:
        skill: trekify
        method: PROBE
        parameters:
          composer: "e8587ace"
          probes: [secrets, infrastructure]
      
      # Output:
      # FINDINGS:
      # - [CRITICAL] API key pattern in thinking block line 423
      # - [HIGH] Internal hostname in tool call line 156
      # - [MEDIUM] Private IP address in context assembly
      # 
      # Risk Score: HIGH
      # Recommendation: Run MASK-SESSION before sharing

  PROBE-SECRETS:
    description: "Hunt specifically for leaked credentials"
    composes_with: cursor-mirror
    parameters:
      composer:
        type: string
      deep_scan:
        type: boolean
        default: true
        description: "Include SQL database scan"
    patterns:
      - "API keys: sk-*, api_key=*, OPENAI_API_KEY"
      - "AWS: AKIA*, aws_secret_access_key"
      - "Passwords: password=*, passwd:*"
      - "Tokens: bearer *, jwt=*, token="
      - "Private keys: -----BEGIN.*PRIVATE KEY-----"
      - "Connection strings: postgres://, mysql://, mongodb://"
    commands:
      - "cursor-mirror tgrep 'sk-[a-zA-Z0-9]{20,}'"
      - "cursor-mirror tgrep 'AKIA[A-Z0-9]{16}'"
      - "cursor-mirror tgrep 'password[=:]'"
      - "cursor-mirror tgrep 'BEGIN.*PRIVATE KEY'"

  PROBE-INFRASTRUCTURE:
    description: "Hunt for internal infrastructure details"
    composes_with: cursor-mirror
    parameters:
      composer:
        type: string
    patterns:
      - "Internal hostnames: *.internal, *.local, *.corp"
      - "Private IPs: 10.*, 192.168.*, 172.16-31.*"
      - "Cloud resources: arn:aws:*, projects/*/locations/*"
      - "Non-standard ports in URLs"
    commands:
      - "cursor-mirror tgrep '\\.internal|\\.local|\\.corp'"
      - "cursor-mirror tgrep '10\\.[0-9]+\\.[0-9]+\\.[0-9]+'"
      - "cursor-mirror tgrep 'arn:aws:'"

  PROBE-PROPRIETARY:
    description: "Hunt for proprietary/internal terms"
    composes_with: cursor-mirror
    parameters:
      composer:
        type: string
      terms_file:
        type: string
        default: ".moollm/trekify/proprietary-terms.txt"
        description: "File with proprietary terms to hunt"
    note: |
      Create .moollm/trekify/proprietary-terms.txt with your
      internal product names, project codenames, customer
      identifiers â€” one per line.

  PROBE-CONTEXT:
    description: "Hunt for sensitive contexts using LLM understanding"
    composes_with: cursor-mirror
    parameters:
      composer:
        type: string
      contexts:
        type: array
        default:
          - security_vulnerabilities
          - incident_response
          - hr_personnel
          - financial_data
          - legal_compliance
    approach: |
      Uses LLM semantic understanding, not just regex.
      "This looks like an incident response discussion" â†’
      flag entire section for review, not just keywords.

  PROBE-AND-MASK:
    description: "Run probes and auto-mask all findings"
    composes_with: cursor-mirror
    parameters:
      composer:
        type: string
      output_path:
        type: string
      probes:
        type: array
        default: [all]
      review_before_mask:
        type: boolean
        default: true
        description: "Show findings for approval before masking"
    returns:
      findings: array
      masked_path: string
      substitutions: array
    workflow:
      - "1. Run all requested probes"
      - "2. Aggregate findings"
      - "3. If review_before_mask: show findings, await approval"
      - "4. Apply MASK-SESSION with all findings"
      - "5. Return masked output"

# WORKFLOW

workflow:
  before_commit:
    description: "Mask sensitive data before committing to public repo"
    steps:
      - "SCAN staged files for sensitive data"
      - "Review findings and adjust sensitivity"
      - "MASK-FILE for each file needing redaction"
      - "Commit masked versions"
      - "Store substitution keys securely (NOT in repo)"
  
  before_sharing_session:
    description: "Mask cursor-mirror transcript before sharing"
    steps:
      - "cursor-mirror agent-transcript <id> > raw.txt"
      - "trekify MASK-SESSION â†’ masked.txt"
      - "Review masked output"
      - "Share masked version"
  
  in_commit_messages:
    description: "Use TREKIFY style in thoughtful-commitment"
    example: |
      # Instead of:
      fix: Update AWS credentials for prod-payments service
      
      # Write:
      fix: Recalibrate quantum authentication at Utopia Planitia
      
      The isolinear encryption sequence for the payment processing
      matrix approached temporal decay threshold. Rotated quantum
      harmonics and updated the orchestration manifest in Sector 001.

# EXAMPLES

examples:
  
  connection_string:
    before: "postgresql://admin:secretpass@prod-db.company.com:5432/userdata"
    after: "Memory Core uplink via biometric phase harmonics to Starbase 47, docking frequency 54, userdata archive"
  
  log_entry:
    before: |
      2024-01-15 10:23:45 ERROR Failed to connect to api-server-3.internal
      Auth token expired for user john.smith@company.com
      Retrying with new credentials from AWS Secrets Manager
    after: |
      Stardate 2024.015 1023 ALERT Uplink failure to Starbase 3
      Subspace authentication matrix expired for Lieutenant Smith
      Reinitializing quantum relay via Utopia Planitia credential vault
  
  commit_message:
    before: |
      fix: Rotate API keys after security audit
      
      The penetration test found our Stripe keys were exposed in
      the staging environment. Rotated all keys and updated the
      Kubernetes secrets in us-east-1 and eu-west-1.
    after: |
      fix: Rotate quantum entanglement tokens after security diagnostic
      
      Level-4 security sweep detected credential exposure in the
      holodeck test matrix. Refreshed all authentication harmonics
      and updated orchestration manifests in Sectors 001 and 012.

# GEORDI SAYS

geordi_says: |
  "Captain, I've completed the privacy diagnostic. All sensitive data
  has been routed through the technobabble filters. The quantum
  signatures are masked but readable, and the narrative flow is
  maintained. We're ready to share the logs with external teams.
  
  The substitution key is stored in the secure isolinear vault â€”
  we can reverse the process if needed for internal review.
  
  Estimated time to full disclosure: whenever you give the order, sir."
