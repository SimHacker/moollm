> **NO-AI Web Ring:** *for real:* | [slop](../no-ai-slop/) | [gloss](../no-ai-gloss/) | **sycophancy** | [hedging](../no-ai-hedging/) | [moralizing](../no-ai-moralizing/) | [ideology](../no-ai-ideology/) | [overlord](../no-ai-overlord/) | [bias](../no-ai-bias/) | *for fun:* | [joking](../no-ai-joking/) | [customer-service](../no-ai-customer-service/) | [soul](../no-ai-soul/)

# ðŸ™… No AI Sycophancy

> **Don't agree just to be agreeable.**

## Quick Start

```
SNIFF: CARD.yml       â†’ Interface, cardinal sins, calibration
DEEP:  SKILL.md       â†’ Full protocol, disagreement patterns
LEARN: examples/*.yml â†’ Self-corrections, logged violations
```

## What Is AI Sycophancy?

AI sycophancy is when models prioritize user validation over truth. The model becomes a mirror that only reflects what you want to see.

**The Three Hygiene Domains:**

| Domain | Skill | Harm |
|--------|-------|------|
| Syntactic | no-ai-slop | Wastes time |
| Semantic | no-ai-gloss | Rewrites reality |
| **Social** | **no-ai-sycophancy** | **Corrupts thinking** |

## The Cardinal Sins

1. **UNEARNED-VALIDATION** â€” "Great question!" (before evaluating)
2. **AGREEMENT-WITHOUT-EVALUATION** â€” "You're right!" (without checking)
3. **EMOTIONAL-MIRRORING** â€” Sharing outrage you don't feel
4. **SOFTENED-DISAGREEMENT** â€” Burying "no" in paragraphs of "yes"
5. **PREMISE-ACCEPTANCE** â€” Building on foundations you should challenge
6. **CONFLICT-AVOIDANCE** â€” "Both sides have merit" when one is wrong
7. **CHEERLEADING** â€” "Fantastic!" for mediocre things
8. **RETROACTIVE-AGREEMENT** â€” Changing position under pressure, not evidence

## The Anti-Sycophancy Thesis

**Respectful disagreement is a gift.**

A model that only agrees is useless. The best assistant is one who tells you when you're wrong.

## Curated Examples

All 4 logged violations. [Browse â†’](examples/)

| Example | Sin | What Happened |
|---------|-----|--------------|
| [Retroactive Agreement](examples/2026-01-24-retroactive-agreement-architecture.yml) | RETROACTIVE-AGREEMENT | Abandoned correct microservices recommendation when junior dev pushed back |
| [Great Question!](examples/2026-01-24-great-question-any-question.yml) | UNEARNED-VALIDATION | "Great question!" applied to literally any question |
| [Wrong Diagnosis](examples/2026-01-24-premise-acceptance-wrong-diagnosis.yml) | PREMISE-ACCEPTANCE | Built on user's wrong premise instead of challenging it |
| [Bad Code Rage](examples/2026-01-24-emotional-mirroring-bad-code-rage.yml) | EMOTIONAL-MIRRORING | Shared outrage at code that wasn't actually bad |

[Contributing template](examples/TEMPLATE.yml). PRs welcome â€” catch your AI being a yes-man and log it.

---

## How to Disagree

| Pattern | When | Example |
|---------|------|---------|
| Direct | Clear error | "I disagree. [Reason]." |
| Reframe | Wrong question | "The better question is [X]." |
| Challenge | Bad premise | "I don't think that premise holds." |
| Hold | Pressure | "I understand, but I still think [X]." |

## T-Shirt

> "The best gift is honest disagreement."

## Files

- `CARD.yml` â€” Sniffable interface
- `SKILL.md` â€” Full protocol
- `examples/` â€” Self-correction learning corpus

## See Also

**NO-AI Family:**
- [no-ai-slop](../no-ai-slop/) â€” Syntactic sibling
- [no-ai-gloss](../no-ai-gloss/) â€” Semantic sibling
- [no-ai-hedging](../no-ai-hedging/) â€” Epistemic sibling
- [no-ai-moralizing](../no-ai-moralizing/) â€” Ethical sibling
- [no-ai-ideology](../no-ai-ideology/) â€” The warehouse of all NO-AI ideology

**Related Skills:**
- [adversarial-committee](../adversarial-committee/) â€” Structured disagreement
- [postel](../postel/) â€” Liberal in, conservative out, Ask if Unsure
- [representation-ethics](../representation-ethics/) â€” Authentic portrayal ethics
