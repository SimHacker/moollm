# CARD.yml â€” Slideshow
#
# Present images in linear narrative form.
# "The camera is the pickaxe. The slideshow is the museum."

card:
  id: slideshow
  name: "Slideshow"
  type: [skill, presentation, narrative, images]
  emoji: ğŸï¸
  rarity: uncommon
  
  description: |
    Present generated images as linear visual narratives.
    Synthesize metadata (prompts, mined resources) into stories.
    Create scrollable galleries for GitHub, social media, documentation.
    
    Visualizer CREATES. Slideshow PRESENTS.

# MOOLLM K-LINES

k-lines:
  related:
    - { ref: visualizer, meaning: "Creates the images we present" }
    - { ref: image-mining, meaning: "Extracts resources we summarize" }
    - { ref: storytelling-tools, meaning: "Narrative structure and arc" }
    - { ref: yaml-jazz, meaning: "Metadata as semantic fuel" }
    - { ref: room, meaning: "Spatial context for scenes" }
    - { ref: character, meaning: "Who appears in images" }

# TOOLS

tools:
  required: [read_file, write_file]
  optional: [run_terminal_cmd]

tier: 1  # Reading/writing markdown, no execution

# TEMPLATES
#
# Two templates: README.md (landing page) and SLIDESHOW.md (story)
# GitHub renders README.md automatically â€” use it as the front door.

templates:
  README.md.tmpl:
    purpose: "GitHub landing page â€” metadata, links, motivation"
    philosophy: |
      README.md = Front door (shown on GitHub automatically)
      SLIDESHOW.md = Pure story (no metadata clutter)
    placeholders:
      header:
        - "{{emoji}} â€” Gallery emoji"
        - "{{title}} â€” Gallery title"
        - "{{tagline}} â€” One-line hook"
        - "{{overview}} â€” 2-3 sentence intro"
      gallery_info:
        - "{{slide_count}} â€” Number of images"
        - "{{date}} â€” Creation date"
        - "{{style}} â€” Narrative style"
        - "{{primary_location}} â€” Main setting"
      characters:
        - "{{#each characters}} â€” Featured characters loop"
        - "{{name}}, {{emoji}}, {{link}}, {{role_in_gallery}}"
      locations:
        - "{{#each locations}} â€” Locations loop"
        - "{{name}}, {{link}}, {{description}}"
      story:
        - "{{story_summary}} â€” Fresh synthesis motivating the reader"
      technical:
        - "{{mining_layers}} â€” Which AI layers mined"
        - "{{generator}} â€” Who created this"
    instructions: "See template file for full documentation"
    
  SLIDESHOW.md.tmpl:
    purpose: "Pure story template â€” narrative without metadata"
    philosophy: |
      The story flows uninterrupted.
      All metadata lives in README.md landing page.
    placeholders:
      front_matter:
        - "{{title}} â€” Gallery title"
        - "{{date}} â€” Creation date (YYYY-MM-DD)"
        - "{{image_count}} â€” Number of images"
        - "{{style}} â€” Style descriptor"
      header:
        - "{{emoji}} â€” Header emoji"
        - "{{opening_quote}} â€” Evocative opener"
        - "{{overview}} â€” 2-3 sentence description"
      per_image:
        - "{{index}} â€” Shot number"
        - "{{location}} â€” Where in the world"
        - "{{time}} â€” Time of shot"
        - "{{caption}} â€” Brief caption"
        - "{{filename}} â€” Image filename"
        - "{{subjects}} â€” Array of who/what appears"
        - "{{prompt_file}} â€” Prompt sidecar path"
        - "{{mined_file}} â€” Mining sidecar path"
      footer:
        - "{{style_notes}} â€” Artistic direction notes"
        - "{{closing_quote}} â€” Tagline"
    instructions: "See template file for full documentation"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEREO SLIDESHOWS â€” YML (truth) + MD (narrative)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

stereo:
  philosophy: |
    A stereo slideshow maintains two complementary files:
    - SLIDESHOW.yml: Machine-readable source of truth (left eye)
    - SLIDESHOW.md: Human-readable narrative for GitHub (right eye)
    
    Together they provide depth perception:
    - YML is for compilers, tools, and structured queries
    - MD is for humans, GitHub display, and storytelling
    
  yml:
    purpose: "Single source of truth for slideshow metadata"
    consumed_by: ["compile.py", "engine.js", "validators"]
    contains:
      - id: "Unique slideshow identifier"
      - name: "Human-readable name"
      - location: "Room reference (room/...)"
      - contents: "Array of photo entries"
      - narrative: "Hints for MD generation"
      
  md:
    purpose: "GitHub-displayable narrative presentation"
    generated_from: "SLIDESHOW.yml via SYNC command"
    contains:
      - frontmatter: "inherits, title, created, images"
      - narrative: "Prose descriptions, quotes, captions"
      - images: "Inline image embeds"
      - links: "Prompt/mining file references"
      
  sync:
    direction: "YML â†’ MD (one-way generation)"
    command: "SYNC SLIDESHOW [directory]"
    preserves: "Manual narrative additions in MD (if marked)"

# METHODS

methods:
  SYNC:
    description: "Regenerate SLIDESHOW.md from SLIDESHOW.yml"
    parameters:
      directory: "Directory containing SLIDESHOW.yml"
    output: file (SLIDESHOW.md)
    invoked_by: [player, script, auto]
    note: "Use after editing YML to update the narrative view"
    
  CREATE_STEREO:
    description: "Create both SLIDESHOW.yml and SLIDESHOW.md"
    signature: "CREATE STEREO SLIDESHOW FOR [directory]"
    parameters:
      directory: "Directory containing photos"
      title: "Gallery title"
    output: files (SLIDESHOW.yml, SLIDESHOW.md)
    invoked_by: [player, script, auto]
    note: "Scans directory, creates YML, generates MD from YML"
    
  UPDATE_YML:
    description: "Update SLIDESHOW.yml with new photos"
    parameters:
      directory: "Directory containing SLIDESHOW.yml"
    output: file (updated SLIDESHOW.yml)
    invoked_by: [player, script, auto]
    note: "Does NOT auto-update MD; run SYNC after"
    
  CREATE:
    description: "Create SLIDESHOW.md for a directory of images"
    parameters:
      directory: "Directory containing images (default: current)"
      title: "Gallery title"
      style: "Narrative style (timeline, journey, comparison, random)"
    output: file (SLIDESHOW.md)
    invoked_by: [player, script, auto]
    note: "Often followed by LANDING to create README.md"
    
  LANDING:
    description: "Create README.md landing page for GitHub display"
    signature: "LANDING [directory] (FOR [slideshow])"
    parameters:
      directory: "Directory containing SLIDESHOW.md"
      slideshow: "Path to SLIDESHOW.md (default: ./SLIDESHOW.md)"
    output: file (README.md)
    philosophy: |
      GitHub renders README.md automatically, not SLIDESHOW.md.
      Use README.md as the front door:
        - Title, tagline, metadata table
        - Featured characters (with links)
        - Featured locations (with links)
        - Fresh story summary (not copy-paste from SLIDESHOW)
        - Link into the actual story
      
      The SLIDESHOW.md stays pure narrative â€” no clutter.
    inputs:
      - "SLIDESHOW.md â€” the story to summarize"
      - "-mined.yml files â€” character/location details"
      - "Character directories â€” for linking"
      - "Room directories â€” for linking"
    invoked_by: [player, script, auto]
    typically_after: [CREATE, ORGANIZE]
    
  UPDATE:
    description: "Add new images to existing SLIDESHOW.md"
    parameters:
      directory: "Directory containing SLIDESHOW.md"
      images: "New images to add (or auto-detect)"
    output: file (updated SLIDESHOW.md)
    invoked_by: [player, script, auto]
    
  SUMMARIZE:
    description: "Create summary from prompt and mining sidecars"
    parameters:
      image: "Image file path"
      prompt_sidecar: "Associated .yml prompt file"
      mining_sidecar: "Associated -mined.yml file"
    output: text (narrative description)
    invoked_by: [CREATE, UPDATE]
    
  ORGANIZE:
    description: "Move SLIDESHOW.md and images into named subdirectory"
    parameters:
      slideshow: "Path to SLIDESHOW.md"
      name: "Subdirectory name (lowercase-dashed)"
    output: directory (reorganized files)
    invoked_by: [player]
    
  COMPARE:
    description: "Cross-image comparison section"
    parameters:
      images: "Images to compare"
      criteria: "Comparison criteria (style, mood, subject, etc.)"
    output: text (comparison section)
    invoked_by: [CREATE, UPDATE]

# SLIDESHOW STRUCTURE

structure:
  front_matter:
    inherits: slideshow
    title: string
    created: datetime
    images_count: number
    
  sections:
    - header: "# Title and intro quote"
    - overview: "Brief description of the gallery"
    - gallery: "Image entries with descriptions"
    - stats: "Summary table"
    - style_notes: "Artistic direction"
    - connections: "James Burke style links"
    
  entry_format: |
    ## ğŸ“ Shot N: Location (Time)
    
    ### *"Caption quote"*
    
    ![Alt text](image-file.png)
    
    **Location:** Where this was taken
    
    **Who's Here:**
    - ğŸ‘© Character 1 description
    - ğŸ’ Character 2 description
    
    ğŸ“ **Files:** [Prompt](prompt.yml) | [Resources](prompt-mined.yml)

# INHERITANCE

inheritance:
  pattern: |
    SLIDESHOW.md files should declare inheritance:
    
    ```yaml
    ---
    inherits: slideshow
    title: "Gallery Title"
    created: 2026-01-19
    ---
    ```
    
    This enables:
    - Consistent structure
    - Auto-update capabilities
    - Gallery discovery
    - Cross-slideshow linking

# ORGANIZATION PATTERN

organization:
  pattern: |
    When a directory accumulates images, ORGANIZE them:
    
    BEFORE:
      pub/
        SLIDESHOW.md
        image-1.png
        image-1.yml
        image-1-mined.yml
        image-2.png
        ...
    
    AFTER:
      pub/
        dons-pub-photos-2026-01-19/
          SLIDESHOW.md
          image-1.png
          image-1.yml
          image-1-mined.yml
          image-2.png
          ...
    
  naming: "lowercase-dashes, descriptive, date-suffixed if temporal"

# ADVERTISEMENTS

advertisements:
  PRESENT-IMAGES:
    score: 90
    condition: "Directory has images needing gallery"
    
  UPDATE-GALLERY:
    score: 85
    condition: "New images added to directory with SLIDESHOW.md"
    
  ORGANIZE-GALLERY:
    score: 80
    condition: "SLIDESHOW.md has many images, needs own directory"
    
  SUMMARIZE-METADATA:
    score: 75
    condition: "Images have sidecars, need narrative synthesis"

# STATE

state:
  current_slideshow:
    path: { type: path }
    image_count: { type: number }
    last_updated: { type: datetime }
  pending_images:
    paths: { type: array }

# OUTPUT TARGETS

targets:
  github:
    description: "GitHub markdown rendering"
    features:
      - "Inline images"
      - "Collapsible sections"
      - "Tables"
      - "Emoji support"
    note: "Primary target â€” death-scrollable on mobile and desktop"
    
  social:
    description: "Social media friendly excerpts"
    features:
      - "Tweet-sized summaries"
      - "Single image + caption"
      - "Thread structure"
      
  presentation:
    description: "Slide deck generation"
    features:
      - "One image per slide"
      - "Speaker notes from metadata"
    future: true

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPILED OUTPUT â€” What gets baked into web apps
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

compiled:
  description: |
    When compiling a slideshow for web app distribution, include:
    - Full image URLs (GitHub raw, CDN, or bundled)
    - Complete prompts and generation settings
    - All mining layer content
    - Simulated EXIF metadata
    - Source file contents (PHOTO.yml, PHOTO.md)
    
  include:
    - github_links           # URLs to raw images
    - prompt_full            # Complete generation prompt
    - prompt_negative        # Negative prompt if any
    - generator_settings     # DALL-E/Midjourney/SD settings
    - sources_yaml           # Full PHOTO.yml content
    - sources_md             # Full PHOTO.md content
    - mining_all             # All MINING-*.md/yml files
    - simulated_exif         # Full fake camera metadata
    - creation_history       # Version history

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SIMULATED PHOTOGRAPHY METADATA â€” Full Monty EXIF for AI images
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# Even AI-generated images get "camera metadata" for the visualizer skill.
# This guides regeneration, style matching, and creative direction.
# Each photo can override slideshow defaults.
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

simulated_exif:

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # CAMERA BODY
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  camera:
    schema:
      make: { type: string, example: "MOOST Optical", default: "MOOST Optical" }
      model: { type: string, example: "Semantic Eye Mark IV" }
      serial: { type: string, example: "SE4-2026-NO-AI-001" }
      firmware: { type: string, example: "v4.2.1-stereo" }
      sensor_type: { type: string, enum: ["full-frame", "aps-c", "medium-format", "film"] }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # LENS
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  lens:
    schema:
      make: { type: string, example: "Constructionist Glass" }
      model: { type: string, example: "Wide Reality 24-70mm f/2.8" }
      focal_length: { type: number, unit: mm, example: 28 }
      focal_length_35mm_equiv: { type: number, unit: mm }
      max_aperture: { type: number, example: 2.8 }
      min_aperture: { type: number, example: 22 }
      filter: { type: string, enum: ["none", "UV", "polarizer", "ND2", "ND4", "ND8", "graduated-ND", "warming", "cooling"] }
      hood: { type: boolean, default: true }
      vintage: { type: boolean, default: false }
      adapted: { type: boolean, note: "Using adapter from different mount" }
      
    presets:
      wide: { focal_length: 24, max_aperture: 2.8, note: "Architecture, landscapes" }
      standard: { focal_length: 50, max_aperture: 1.4, note: "Human perspective" }
      portrait: { focal_length: 85, max_aperture: 1.4, note: "Flattering compression" }
      telephoto: { focal_length: 200, max_aperture: 2.8, note: "Distant subjects" }
      macro: { focal_length: 100, max_aperture: 2.8, note: "Extreme close-up" }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # EXPOSURE
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  exposure:
    schema:
      mode: { type: string, enum: ["manual", "aperture-priority", "shutter-priority", "program", "auto"] }
      aperture: { type: number, unit: "f-stop", example: 5.6 }
      shutter_speed: { type: string, example: "1/60" }
      iso: { type: number, example: 400 }
      ev_compensation: { type: number, default: 0 }
      metering_mode: { type: string, enum: ["matrix", "center-weighted", "spot", "highlight"] }
      exposure_lock: { type: boolean }
      bracketing: { type: string, enum: ["none", "3-shot", "5-shot", "HDR"] }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # FOCUS
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  focus:
    schema:
      mode: { type: string, enum: ["manual", "single-af", "continuous-af", "eye-af", "zone"] }
      distance: { type: number, unit: meters }
      depth_of_field: { type: string, enum: ["razor-thin", "shallow", "medium", "deep", "hyperfocal"] }
      hyperfocal: { type: boolean }
      focus_stacking: { type: boolean, note: "Multiple focus points combined" }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # FILM / SENSOR SIMULATION
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  film:
    schema:
      type: { type: string, example: "Portra 400" }
      format: { type: string, enum: ["35mm", "medium-format-6x6", "medium-format-6x7", "large-format-4x5", "large-format-8x10", "instant", "digital"] }
      push_pull: { type: number, default: 0, note: "Stops pushed (+) or pulled (-)" }
      grain: { type: string, enum: ["none", "fine", "medium", "heavy", "extreme"] }
      color_profile: { type: string, enum: ["neutral", "warm", "cool", "saturated", "muted", "cross-processed", "infrared"] }
      dynamic_range: { type: string, enum: ["low", "medium", "high", "HDR"] }
      expired: { type: boolean, note: "Expired film aesthetic" }
      
    presets:
      portra_400: { type: "Kodak Portra 400", grain: "fine", color_profile: "warm", note: "Portrait standard" }
      ektar_100: { type: "Kodak Ektar 100", grain: "fine", color_profile: "saturated", note: "Vivid landscapes" }
      tri_x: { type: "Kodak Tri-X 400", grain: "medium", color_profile: "neutral", note: "Classic B&W" }
      hp5: { type: "Ilford HP5+", grain: "medium", color_profile: "neutral", note: "Flexible B&W" }
      cinestill_800t: { type: "CineStill 800T", grain: "medium", color_profile: "cool", note: "Tungsten cinema" }
      velvia_50: { type: "Fuji Velvia 50", grain: "fine", color_profile: "saturated", note: "Punchy slides" }
      polaroid_sx70: { type: "Polaroid SX-70", format: "instant", grain: "heavy", note: "Instant nostalgia" }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # LIGHTING CONDITIONS
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  lighting:
    schema:
      time_of_day: { type: string, enum: ["blue-hour-dawn", "golden-hour-morning", "morning", "noon", "afternoon", "golden-hour-evening", "blue-hour-dusk", "night", "deep-night"] }
      sun_position: { type: string, enum: ["below-horizon", "low", "medium", "high", "overhead", "behind-subject", "side"] }
      golden_hour: { type: boolean }
      blue_hour: { type: boolean }
      artificial: { type: array, items: { source: string, color: string, intensity: string } }
      ambient: { type: string, enum: ["none", "very-low", "low", "medium", "high", "bright"] }
      contrast: { type: string, enum: ["flat", "low", "medium", "high", "extreme"] }
      direction: { type: string, enum: ["front", "side", "back", "top", "bottom", "diffuse"] }
      quality: { type: string, enum: ["hard", "soft", "dappled", "mixed"] }
      
    artificial_sources:
      - neon: { colors: ["pink", "blue", "green", "orange", "white", "red"] }
      - fluorescent: { colors: ["cool-white", "warm-white", "green-tint"] }
      - tungsten: { colors: ["warm-orange"] }
      - led: { colors: ["daylight", "warm", "rgb"] }
      - sodium: { colors: ["orange"] }
      - mercury: { colors: ["blue-green"] }
      - candle: { colors: ["warm-yellow"] }
      - fire: { colors: ["orange-red", "flickering"] }
      - screen: { colors: ["blue", "white"] }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # FLASH
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  flash:
    schema:
      used: { type: boolean, default: false }
      mode: { type: string, enum: ["off", "fill", "bounce", "direct", "rear-curtain", "slow-sync", "high-speed-sync"] }
      power: { type: string, enum: ["1/128", "1/64", "1/32", "1/16", "1/8", "1/4", "1/2", "full"] }
      modifier: { type: string, enum: ["none", "diffuser", "bounce-card", "softbox", "umbrella", "grid", "gel"] }
      color_gel: { type: string, note: "CTO, CTB, or creative color" }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # TRIPOD / STABILITY
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  support:
    schema:
      tripod: { type: boolean }
      tripod_type: { type: string, enum: ["aluminum", "carbon-fiber", "travel", "studio", "monopod", "gorilla-pod"] }
      head_type: { type: string, enum: ["ball-head", "pan-tilt", "gimbal", "fluid-video", "geared"] }
      image_stabilization: { type: string, enum: ["off", "on", "on-tripod-mode"] }
      handheld: { type: boolean }
      braced: { type: boolean, note: "Leaning against something" }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # WEATHER
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  weather:
    schema:
      conditions: { type: string, enum: ["clear", "partly-cloudy", "overcast", "fog", "mist", "light-rain", "heavy-rain", "snow", "storm"] }
      temperature_c: { type: number }
      humidity_percent: { type: number }
      wind: { type: string, enum: ["still", "light-breeze", "moderate", "strong", "gusty"] }
      precipitation: { type: string, enum: ["none", "drizzle", "rain", "snow", "sleet", "hail"] }
      visibility: { type: string, enum: ["excellent", "good", "moderate", "poor", "fog"] }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # GPS / LOCATION (simulated)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  gps:
    schema:
      latitude: { type: number }
      longitude: { type: number }
      altitude_m: { type: number }
      location_name: { type: string }
      accuracy_m: { type: number }
      world: { type: string, note: "Fictional world name if not Earth" }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # TIMESTAMP
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  datetime:
    schema:
      captured: { type: datetime, format: "ISO8601" }
      timezone: { type: string, example: "America/Los_Angeles" }
      solar_time: { type: string, note: "Actual sun position time" }
      season: { type: string, enum: ["spring", "summer", "autumn", "winter"] }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # POST-PROCESSING
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  post_processing:
    schema:
      raw_converter: { type: string, example: "Semantic Lightroom" }
      adjustments:
        exposure: { type: number, range: [-5, 5] }
        contrast: { type: number, range: [-100, 100] }
        highlights: { type: number, range: [-100, 100] }
        shadows: { type: number, range: [-100, 100] }
        whites: { type: number, range: [-100, 100] }
        blacks: { type: number, range: [-100, 100] }
        clarity: { type: number, range: [-100, 100] }
        vibrance: { type: number, range: [-100, 100] }
        saturation: { type: number, range: [-100, 100] }
        temperature: { type: number, range: [2000, 50000], unit: kelvin }
        tint: { type: number, range: [-150, 150] }
      crop: { type: boolean }
      crop_ratio: { type: string, enum: ["original", "1:1", "4:3", "3:2", "16:9", "5:4", "custom"] }
      rotation: { type: number, unit: degrees }
      lens_correction: { type: boolean }
      chromatic_aberration_fix: { type: boolean }
      vignette: { type: number, range: [-100, 100] }
      grain_added: { type: number, range: [0, 100] }
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # CREATIVE INTENT
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  creative:
    schema:
      style: { type: string, enum: ["documentary", "cinematic", "portrait", "landscape", "street", "fine-art", "commercial", "editorial", "abstract", "experimental"] }
      mood_target: { type: array, items: string }
      reference_photographers: { type: array, items: string }
      reference_films: { type: array, items: string }
      reference_paintings: { type: array, items: string }
      era: { type: string, enum: ["1900s", "1920s", "1940s", "1950s", "1960s", "1970s", "1980s", "1990s", "2000s", "2010s", "2020s", "timeless", "futuristic"] }
      
    # VISUAL PRESETS LIVE IN VISUALIZER
    # Photographers, film stocks, devices, profiles â€” see visualizer skill
    photographer_presets: 
      see: "skills/visualizer/photographers/"
      note: "Visual style presets belong in visualizer, not slideshow"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VISUALIZER REFERENCE â€” Where visual creation presets live
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# Slideshow PRESENTS images. Visualizer CREATES them.
# All visual style presets are in the visualizer skill.
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

visualizer_presets:
  note: |
    Slideshow doesn't own visual presets â€” visualizer does.
    Use these for image GENERATION, slideshow for PRESENTATION.
    
  see: "skills/visualizer/"
  
  photographers: "skills/visualizer/photographers/"
  cameras: "skills/visualizer/cameras/"
  film: "skills/visualizer/film/"
  profiles: "skills/visualizer/profiles/"
  styles: "skills/visualizer/styles/"
  
  commands:
    - "TAKE PHOTO AS don OF scene"       # Character POV
    - "PARTY PHOTO OF scene"             # Multiple perspectives
    - "visualize.py scene.yml --film portra_400"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PHOTO ENTRY SCHEMA â€” What each photo in a slideshow contains
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

photo_schema:
  required:
    dir: { type: string, note: "Directory name for this photo" }
    subject: { type: string, note: "What the photo shows" }
    
  recommended:
    mood: { type: string }
    status: { type: string, enum: ["planned", "generating", "generated", "curated"] }
    image: { type: string, note: "Filename of primary image" }
    sources:
      left_eye: { type: string, default: "PHOTO.yml" }
      right_eye: { type: string, default: "PHOTO.md" }
    mining: { type: array, note: "List of MINING-*.md/yml files" }
    simulated_exif: { type: object, note: "Override slideshow EXIF defaults" }
    
  optional:
    visual_joke: { type: string }
    quality: { type: string, enum: ["POOR", "OK", "GOOD", "EXCELLENT", "MASTERPIECE"] }
    role: { type: string, enum: ["COVER_PHOTO", "ESTABLISHING", "DETAIL", "TRANSITION", "CLIMAX", "CLOSING"] }
    vibe: { type: string }
    alternatives: { type: array, note: "List of alternate versions" }
    
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DISTRIBUTED NAMING â€” Conflict-free collaborative creation
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

distributed_naming:
  pattern: "{ISO8601-timestamp}-{userid}-{slug}/"
  example: "20260125T193000Z-don-dusk-neon/"
  
  rationale: |
    NO sequential numbers (000, 001) â€” causes merge conflicts!
    Timestamp-userid prefixes are globally unique.
    
  benefits:
    - no_conflicts: "Everyone creates independently, git merge just works"
    - natural_ordering: "Sort alphabetically = chronological"
    - attribution: "Creator always visible in path"
    - forkable: "based_on field tracks remix lineage"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PRIMARY / VERSIONED / MINE â€” The Dreaming Pattern
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# Images accumulate versions. Mines dream across all of them.
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

image_versioning:
  
  philosophy: |
    The PRIMARY image has no timestamp prefix â€” it's the canonical "now."
    Historical versions get timestamped when they lose primary status.
    The MINE file accumulates impressions across ALL versions.
    
    It's a dream that remembers every face the image has worn.
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # FILE NAMING
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  naming:
    primary:
      pattern: "{description}.{ext}"
      example: "no-ai-tower-exterior.png"
      note: "No timestamp = current canonical version"
      
    versioned:
      pattern: "{YYYY-MM-DD-HH-MM-SS}-{description}.{ext}"
      example: "2026-01-25-19-30-00-no-ai-tower-exterior.png"
      note: "Timestamp prefix = historical version"
      
    sidecar:
      pattern: "{same-base-name}.yml"
      example: "no-ai-tower-exterior.yml"
      note: "Generation recipe, prompts, settings"
      
    mine:
      pattern: "{description}-mine.yml"
      example: "no-ai-tower-exterior-mine.yml"
      note: "Accumulates across ALL versions â€” the dream"
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # SWITCHING PRIMARY
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  switch_primary:
    description: |
      To make a different version the new primary:
      
      1. TIMESTAMP the current primary (archive it)
         no-ai-tower-exterior.png â†’ 2026-01-20-14-30-00-no-ai-tower-exterior.png
         no-ai-tower-exterior.yml â†’ 2026-01-20-14-30-00-no-ai-tower-exterior.yml
         
      2. UNPREFX the new primary (promote it)
         2026-01-25-19-30-00-no-ai-tower-exterior.png â†’ no-ai-tower-exterior.png
         2026-01-25-19-30-00-no-ai-tower-exterior.yml â†’ no-ai-tower-exterior.yml
         
      3. KEEP the mine (it accumulates)
         no-ai-tower-exterior-mine.yml stays as-is
         
    note: "The mine forgets no face. It dreams of all of them."
    
    command: "SWITCH PRIMARY {versioned-file}"
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # MULTI-IMAGE MINING â€” The Dream
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  multi_image_mine:
    description: |
      The mine file accumulates observations across multiple image versions.
      Each regeneration adds new details, perspectives, and impressions.
      Over time, the mine becomes richer than any single image.
      
      It's a dream that combines all the different faces:
      - Details from the first attempt
      - Colors from the second
      - Composition from the third
      - Happy accidents from all of them
      
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # YES AND â€” Semantic Layering Protocol
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    yes_and_protocol:
      description: |
        When mining, ALWAYS show the LLM the existing mine layers.
        The LLM should YES AND â€” build on what's there, not repeat or contradict.
        
      rules:
        show_existing: |
          Always include current mine content in the mining prompt.
          The LLM needs to see what's already been observed.
          
        add_unique: |
          Only add observations that are NEW and UNIQUE.
          If the mine already says "neon sign glows pink" â€” don't repeat it.
          But you CAN build on it: "the pink glow reflects in puddles"
          
        no_contradiction: |
          Don't contradict existing observations unless explicitly correcting.
          If mine says "tower is 5 stories" don't say "3 story building."
          If you see something different, note it as a variant: 
            "in this version, appears shorter â€” perhaps perspective"
          
        yes_and: |
          Improv rule: Accept what's there and ADD to it.
          "The sign glows pink" â†’ YES AND "it flickers slightly at dusk"
          Build layers of meaning, each mining pass enriching the dream.
          
        semantic_layers: |
          Each mining pass can focus on different aspects:
          - First pass: Basic composition, subjects, colors
          - Second pass: Mood, atmosphere, emotional register
          - Third pass: Symbolism, narrative implications
          - Fourth pass: Technical details, photographic qualities
          - Fifth pass: Connections to other images, characters, story
          - Backstory passes: What's NOT shown but implied (see below)
          
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # BACKSTORY LAYERS â€” What the image implies beyond the frame
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    backstory_layers:
      description: |
        Images are artifacts. They imply history, connections, stories.
        Backstory mining reads BACKWARD in time and OUTWARD in space.
        What's NOT shown is as rich as what IS shown.
        
      temporal_depth:
        description: "What happened before this moment was captured?"
        layers:
          - minutes_ago: "The argument that led to this expression"
          - hours_ago: "How they got here, what they were doing"
          - days_ago: "Recent events that shaped this moment"
          - weeks_ago: "Relationships forming, plans hatching"
          - years_ago: "Origin stories, why this place exists"
          - deep_history: "Ancient context, geological/civilizational"
          
        example: |
          Image: Don at the bar, looking tired
          
          minutes_ago: "Just finished telling a long story"
          hours_ago: "Walked here from the heist at No-AI Tower"
          days_ago: "Has been obsessing over the tower's sign"
          weeks_ago: "First noticed the tower on Lane Neverending"
          years_ago: "His fascination with neon started in Baltimore"
          deep_history: "The building was once a telegraph office"
          
      spatial_connections:
        description: "What exists beyond the frame?"
        layers:
          - just_outside: "What's immediately off-camera"
          - nearby: "Other rooms, adjacent spaces"
          - related_places: "Connected locations in the world"
          - far_away: "Distant places this connects to"
          - imaginary: "Places that exist only in memory/dreams"
          
        example: |
          Image: The No-AI Tower sign
          
          just_outside: "Lane Neverending stretches in both directions"
          nearby: "The pub where observers gather to watch"
          related_places: "Other towers in the city, corporate HQ"
          far_away: "The factory where the sign was made"
          imaginary: "The future where AI reads this sign and weeps"
          
      character_connections:
        description: "Who relates to this image but isn't shown?"
        layers:
          - present_but_hidden: "Someone just out of frame"
          - was_here: "Who was here before"
          - will_arrive: "Who's on their way"
          - connected_elsewhere: "Characters who'd care about this"
          - fictional_witnesses: "Who would find this meaningful"
          
        example: |
          Image: Empty pub corner with abandoned drink
          
          present_but_hidden: "The bartender watching from the bar"
          was_here: "Donna, who left in a hurry"
          will_arrive: "Don, looking for her"
          connected_elsewhere: "Richard, wondering where everyone went"
          fictional_witnesses: "Fran Lebowitz would have opinions"
          
      session_connections:
        description: "How does this connect to play sessions?"
        layers:
          - this_session: "What happened in current session"
          - previous_sessions: "Callbacks to earlier adventures"
          - future_seeds: "What this might lead to"
          - cross_session: "Connections across different plays"
          - meta_layer: "The players behind the characters"
          
      artifact_history:
        description: "The image AS an object in the world"
        layers:
          - creation: "Who took this photo? When? Why?"
          - discovery: "How was it found? By whom?"
          - significance: "Why does it matter to characters?"
          - secrets: "What does it reveal that wasn't meant to be seen?"
          - future: "What will happen to this image?"
          
        example: |
          This photo of the No-AI Tower was taken by:
          
          creation: "Don, on his first night exploring Lane Neverending"
          discovery: "Found in his camera roll weeks later"
          significance: "Became the centerpiece of his heist planning"
          secrets: "Shows a figure in the window nobody noticed"
          future: "Will be evidence in a future investigation"
          
      backstory_prompt: |
        You are mining image {filename} for BACKSTORY layers.
        
        What does this image IMPLY but NOT SHOW?
        
        EXISTING MINE (do not repeat, do YES AND):
        ---
        {existing_mine_content}
        ---
        
        Add backstory observations:
        - TEMPORAL: What happened before? (minutes/hours/days/years ago)
        - SPATIAL: What's beyond the frame? (nearby/far/imaginary)
        - CHARACTERS: Who's connected but not shown?
        - SESSIONS: How does this connect to play history?
        - ARTIFACT: What's the story of THIS IMAGE as an object?
        
        Build rich deep history. Make connections to the world.
          
      prompt_template: |
        You are mining image {filename} for semantic layers.
        
        EXISTING MINE (do not repeat, do YES AND):
        ---
        {existing_mine_content}
        ---
        
        Add NEW observations that:
        - Build on existing observations (YES AND)
        - Do NOT repeat what's already noted
        - Do NOT contradict unless correcting an error
        - Add unique details, perspectives, connections
        
        Focus on: {current_mining_layer}
        
    schema:
      versions_mined:
        - { timestamp: "2026-01-20T14:30:00Z", provider: "dalle3", notes: "First attempt" }
        - { timestamp: "2026-01-25T19:30:00Z", provider: "imagen4", notes: "Better lighting" }
        
      accumulated_observations:
        - { source: "2026-01-20", observation: "Sign glows pink at dusk" }
        - { source: "2026-01-25", observation: "Reflection in wet pavement" }
        - { source: "combined", observation: "The tower watches Lane Neverending" }
        
      resources:
        # Standard mining layers accumulate
        beauty: { intensity: 0.8, from: ["all"] }
        mystery: { intensity: 0.9, from: ["2026-01-25"] }
        
      dream_synthesis: |
        Optional: LLM-generated synthesis that weaves together
        impressions from all versions into a single narrative.
        "The tower has worn many faces in our dreams..."
        
    philosophy: |
      Keep the mine. Add to it. Let it grow.
      The dream remembers what no single image can hold.
      
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # DIRECTORY EXAMPLE
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  example_directory: |
    no-ai-tower/
      # PRIMARY (no timestamp)
      no-ai-tower-exterior.png          â† Current canonical image
      no-ai-tower-exterior.yml          â† Current generation recipe
      no-ai-tower-exterior-mine.yml     â† Accumulated dream (all versions)
      
      # HISTORICAL (timestamped)
      2026-01-20-14-30-00-no-ai-tower-exterior.png
      2026-01-20-14-30-00-no-ai-tower-exterior.yml
      2026-01-22-09-15-00-no-ai-tower-exterior.png
      2026-01-22-09-15-00-no-ai-tower-exterior.yml
      
      # The mine remembers them all
      # Each version added observations before being archived

# RELATED

see-also:
  - skills/visualizer        # Creates the images we present
  - skills/image-mining      # Extracts resources we summarize
  - skills/storytelling-tools
  - skills/markdown
  - skills/room
  - skills/character
