# CARD.yml â€” Image Mining
#
# SNIFFABLE INTERFACE â€” see SKILL.md for full documentation
# "I mine pixels for atoms. Reality is just compressed resources."
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# THE DOUBLE MEANING â€” Why It's Called "Image MINE"
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# The name "Image Mining" contains a DELIBERATE DOUBLE PUN:
#
# 1. MINE (verb) â€” to extract valuable resources from
#    Like a miner extracting gold from rock,
#    we extract semantic treasures from pixels.
#    The image is the ore. The YAML Jazz is the refined output.
#
# 2. MINE (possessive) â€” belonging to me!
#    Like Daffy Duck lunging at treasure:
#    "MINE! MINE! MINE! ALL MINE!!!"
#    
#    When you mine an image, you CLAIM it.
#    You own its meaning. Its resources become YOURS.
#    The mined YAML is YOUR interpretation.
#    
# The result: "image mine" = both the extracted treasure
# AND the possessive claim on meaning.
#
# Think of Daffy Duck in "Ali Baba Bunny" (1957):
#   - Sees treasure cave
#   - Eyes become dollar signs
#   - Dives into gold
#   - "IT'S MINE! I'M RICH! I'M A HAPPY MISER!"
#
# That's the energy. Every image is a treasure cave.
# Every mining pass is Daffy diving into the pile.
# The YAML Jazz is your documented claim: MINE.
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

card:
  id: image-mining
  name: "Image Mining"
  type: [skill, vision, extraction, automation]
  emoji: â›ï¸ğŸ“·
  rarity: uncommon
  tagline: "Mine pixels for atoms. Your camera is a pickaxe."
  
  description: |
    Extract semantic resources from any visual content.
    Works on: photos, screenshots, graphs, PDFs, diagrams.
    Output: YAML Jazz with quantities, intensities, observations.

# K-LINES

k-lines:
  activates:
    - IMAGE-MINING
    - VISUAL-EXTRACTION
    - YAML-JAZZ
  related:
    - { ref: visualizer, relation: "creates images to mine" }
    - { ref: slideshow, relation: "presents mined galleries" }
    - { ref: postal, relation: "camera integration" }

# METHODS â€” signatures only, see SKILL.md for details

methods:
  MINE:
    signature: "MINE [image] (WITH [shopping-list]) (AT [depth])"
    output: "YAML Jazz extraction"
    
  MULTI-LOOK:
    signature: "MULTI-LOOK [image] FOCUS [lens] (AS [miner-id])"
    output: "New layer appended to -mined.yml"
    
  SCAN:
    signature: "SCAN [image]"
    output: "Quick resource preview"
    
  PROSPECT:
    signature: "PROSPECT [direction|DEEP]"
    output: "List of mining targets"

# DEPTH LEVELS

depth_levels:
  - surface      # Objects, materials, colors
  - deep         # Hidden meanings, emotions
  - sensations   # Colors (hex), textures, smells
  - characters   # Identify who appears (needs character files)
  - philosophical # Meaning, symbolism, existence
  - full         # All combined

# LENSES (for MULTI-LOOK)

lenses:
  - technical    # Composition, lighting, color theory
  - narrative    # Who, why, what moment
  - cultural     # Language markers, traditions
  - emotional    # Expressions, body language
  - symbolic     # Metaphors, hidden meanings
  - character    # Identity, relationships
  - character-deep # Match against character files
  - historical   # Art history, period markers
  - cast-list    # Exhaustive identification

# ADVERTISEMENTS

advertisements:
  MINE-IMAGE:
    score: 95
    condition: "Have image, want semantic resources"
    
  MULTI-LOOK-MINING:
    score: 88
    condition: "Image has existing mining, want deeper interpretation"
    
  EXTRACT-COLORS:
    score: 90
    condition: "Need color palette from image"
    
  PHILOSOPHICAL-MINING:
    score: 85
    condition: "Extract deep meaning from visual"

# MODES â€” brief, see SKILL.md for full explanation

modes:
  native:
    description: "LLM reads image directly â€” PREFERRED"
    tier: 0
  remote-with-llm-assembly:
    description: "LLM assembles context, calls vision API"
  multi-model:
    description: "Layer perspectives from different models"
  tool:
    description: "mine.py for automation/batch"
    tier: 2

# SISTER SCRIPT

script:
  name: mine.py
  path: skills/image-mining/mine.py
  commands: [mine, scan, schema, providers]

# ENVIRONMENT

environment:
  OPENAI_API_KEY: { enables: openai }
  GOOGLE_API_KEY: { enables: google }
  ANTHROPIC_API_KEY: { enables: anthropic }

# TOOLS

tools:
  required: [read_file, write_file]
  optional: [run_terminal_cmd]

tier: 2

# EXTENSIBILITY â€” brief, see SKILL.md for analyzer pipeline details

extensibility:
  analyzers: "Pluggable modules: pose, object, OCR, face, leela-models"
  pipeline: "pre-process â†’ analyzers â†’ llm-vision â†’ post-process"
  leela-models: "leela://customer-id/model-name"

# RESOURCE TYPES â€” brief

resource_types:
  - materials    # iron-ore, wood, stone
  - organics     # leaves, seeds, feathers
  - precious     # gold, gems, artifacts
  - characters   # palm, biscuit, marieke (needs metadata)
  - sensations   # colors, textures, smells
  - abstract     # mood, atmosphere, time
  - philosophical # meaning, mortality, beauty

# STATE

state:
  mined_images: []
  last_extraction: null

# RELATED

see-also:
  - skills/visualizer
  - skills/slideshow
  - skills/logistic-container
  - skills/postal

# LINEAGE

lineage:
  parent: [decompose, visualizer]
  inspiration: ["Minecraft mining", "Photography as extraction"]

# DOCUMENTATION POINTERS

documentation:
  SKILL.md:
    - "Â§ YAML Jazz â€” full protocol and examples"
    - "Â§ Operation Modes â€” when to use each"
    - "Â§ Extensible Analyzer Pipeline â€” custom models"
    - "Â§ Character Recognition â€” matching metadata"
    - "Â§ Multi-Look Mining â€” layered interpretation"
    - "Â§ Example Outputs â€” complete mining results"
  PROTOCOL.md: "Concise instructions for LLM context injection"
