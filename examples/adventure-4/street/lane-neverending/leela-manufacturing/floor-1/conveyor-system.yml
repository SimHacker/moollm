# CONVEYOR SYSTEM
# Intake sorting and routing â€” The Leela Pipeline

object:
  id: conveyor-system
  name: "Intake Conveyor System"
  type: infrastructure
  emoji: "ğŸ”„"
  
  tags: [infrastructure, logistics, automation, pipeline]
  
  description: |
    The main conveyor lines trace a flowing pipeline across the floor.
    Video comes in, forks to parallel tracks, converges to insights,
    flows to storage, and emerges as visualized understanding.
    Two parallel model pipelines feed the processors.
    
  examine: |
    INTAKE CONVEYOR SYSTEM â€” THE LEELA PIPELINE
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Follow the flow:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  OBJECT MODEL   â”‚                       â”‚   POSE MODEL    â”‚
    â”‚   DEVELOPMENT   â”‚                       â”‚   DEVELOPMENT   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                         â”‚
             â–¼                                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  OBJECT MODEL   â”‚                       â”‚   POSE MODEL    â”‚
    â”‚    TRAINING     â”‚                       â”‚    TRAINING     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                         â”‚
             â–¼                                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  OBJECT MODEL   â”‚                       â”‚   POSE MODEL    â”‚
    â”‚     DEPLOY      â”‚                       â”‚     DEPLOY      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                         â”‚
             â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
             â”‚              â”‚    VIDEO    â”‚            â”‚
             â”‚              â”‚   (input)   â”‚            â”‚
             â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜            â”‚
             â”‚                     â”‚                   â”‚
             â”‚                â•â•â•â•â•â•§â•â•â•â•â•              â”‚
             â”‚               /           \             â”‚
             â–¼              â–¼             â–¼            â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       OBJECTS        â”‚   â”‚        POSES         â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚ â”‚  Object Detector â”‚ â”‚   â”‚ â”‚  Pose Estimator  â”‚ â”‚
        â”‚ â”‚    (model v2.3)  â”‚ â”‚   â”‚ â”‚    (model v1.8)  â”‚ â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â”‚      (detected)      â”‚   â”‚      (skeletal)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                           â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    INSIGHTS    â”‚
                        â”‚  (understood)  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ PYTHON ACTIONS â”‚
                        â”‚ (high-level)   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚      SQL       â”‚
                        â”‚   (stored)     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â–¼                 â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    PDA     â”‚â”€â”€â”€â–¶â”‚    QUERIES     â”‚
              â”‚  (writes)  â”‚    â”‚  (retrieves)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚  VISUALIZATIONS  â”‚
                             â”‚    (shows)       â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    OBJECT DETECTION PIPELINE (Left Track)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    LINE M-O (Red): Object Model Development
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Red containers from R&D carry new architectures.
    YOLO variants, transformers, attention mechanisms.
    "What if we added more layers?" "What if we added FEWER?"
    
    LINE T-O (Magenta): Object Model Training
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Magenta containers heavy with ImageNet, COCO, custom datasets.
    Loss curves descend. Accuracy climbs. GPUs whir.
    "Epoch 127. mAP: 0.947. Ship it."
    
    DEPLOY BAY O: Object Detector Deployment
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Trained object models validated and hot-swapped.
    Current: yolo-leela-v2.3.7
    Previous: yolo-leela-v2.3.6 (standby for rollback)
    
    LINE O (Blue): Objects Track
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Blue containers carry detected objects â€” bounding boxes,
    classifications, confidence scores. "A cat. 97% sure."
    POWERED BY: yolo-leela-v2.3.7
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    POSE ESTIMATION PIPELINE (Right Track)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    LINE M-P (Coral): Pose Model Development
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Coral containers from R&D carry skeleton architectures.
    Keypoint detectors, temporal models, motion predictors.
    "17 joints? 25 joints? 133 joints?"
    
    LINE T-P (Pink): Pose Model Training
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Pink containers with motion capture data, dance videos,
    sports footage, yoga poses. Training the body reader.
    "PCK@0.5: 0.923. Hands still tricky."
    
    DEPLOY BAY P: Pose Estimator Deployment
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Trained pose models validated and hot-swapped.
    Current: pose-leela-v1.8.2
    Previous: pose-leela-v1.8.1 (standby for rollback)
    
    LINE P (Orange): Poses Track  
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Orange containers carry skeletal data â€” joint positions,
    movement vectors, gesture signatures. "Waving. Definitely waving."
    POWERED BY: pose-leela-v1.8.2
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    LINE V (Purple): Video Intake
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Raw video streams arrive on purple containers.
    Cameras, recordings, live feeds â€” all enter here.
    The line FORKS at Junction Alpha, splitting each stream
    to BOTH the Object and Pose processors simultaneously.
    
    JUNCTION BETA: The Convergence
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Objects and Poses containers MERGE here.
    Blue meets Orange. Context meets Motion.
    "A cat (97%) is waving (definitely)."
    Output: Insight containers (Gold)
    
    LINE I (Gold): Insights Flow
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Gold containers, heavier with understanding.
    Each insight knows what it saw AND what it meant.
    Flows into Python Actions for high-level processing.
    
    LINE A (Green): Python Actions
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Green containers carry executable logic.
    Python scripts consume insights, define high-level actions,
    and emit structured data to SQL tables.
    
    "Cat detected waving" â†’ action: GREETING_DETECTED
                         â†’ emit: events.greetings (timestamp, entity, gesture)
                         â†’ emit: metrics.engagement (score: 0.87)
    
    Actions can:
    â€¢ Aggregate multiple insights into events
    â€¢ Trigger alerts and notifications
    â€¢ Update state machines
    â€¢ Emit to multiple SQL tables
    â€¢ Call external APIs
    â€¢ Schedule follow-up actions
    
    LINE S (Silver): SQL Storage
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Silver containers descend into the SQL tanks below.
    Structured. Indexed. Queryable. Patient.
    Data waits here to be retrieved.
    
    LINE Q (Cyan): Queries
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Cyan containers pull data UP from SQL storage.
    Each query container arrives empty, leaves full.
    "SELECT understanding FROM insights WHERE cat = waving"
    
    PDA STATION (Green): Query Writers
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Personal Data Assistants sit at terminals, crafting queries.
    They translate questions into SQL, intentions into JOINs.
    "What did the cat do?" â†’ SELECT * FROM insights...
    
    LINE Z (Rainbow): Visualizations
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Rainbow containers at journey's end.
    Charts, graphs, dashboards, stories.
    Data made visible. Understanding made beautiful.
    
    SPECIAL ROUTING:
    â€¢ Corrupted video: QUARANTINE (automatic divert)
    â€¢ Unrecognizable poses: "Is that a dance?" desk
    â€¢ Queries that return everything: Optimization intervention
    â€¢ Visualizations too beautiful: Gallery display
    â€¢ Failed training runs: Post-mortem analysis
    â€¢ Model regressions: Rollback bay
    
  state:
    # Object Detection Pipeline
    line_m_o: { speed: "deliberate", items: 2, architectures_pending: 3 }
    line_t_o: { speed: "variable", items: 4, gpus: 4, epoch: 127, mAP: 0.947 }
    deploy_bay_o: { model: "yolo-leela-v2.3.7", accuracy: 0.947, deployed: "2h ago" }
    
    # Pose Estimation Pipeline
    line_m_p: { speed: "deliberate", items: 1, architectures_pending: 2 }
    line_t_p: { speed: "variable", items: 3, gpus: 4, epoch: 89, pck: 0.923 }
    deploy_bay_p: { model: "pose-leela-v1.8.2", accuracy: 0.923, deployed: "1d ago" }
    
    # Data Pipeline
    line_v: { speed: "fast", items: 34, fps: 30 }
    line_o: { speed: "normal", items: 89, objects_detected: 1247 }
    line_p: { speed: "normal", items: 89, poses_tracked: 1247 }
    junction_beta: { merging: true, insights_created: 847 }
    line_i: { speed: "steady", items: 42, understanding_level: "high" }
    line_a: { speed: "fast", items: 38, actions_defined: 156, tables_emitting: 12 }
    line_s: { speed: "variable", items: 156, rows_stored: 2847291 }
    line_q: { speed: "on-demand", active_queries: 23 }
    pda_station: { assistants: 4, queries_written_today: 89 }
    line_z: { speed: "careful", visualizations: 12, beauty_score: 8.7 }
    
  processing_stats:
    object_model_development:
      architectures_proposed: 15
      papers_read: 423
      yolo_variants_tried: 7
      transformer_experiments: 4
      
    object_model_training:
      models_trained_this_week: 8
      gpu_hours: 1847
      best_mAP: 0.947
      datasets: ["COCO", "ImageNet", "Leela-Custom-v3"]
      
    pose_model_development:
      architectures_proposed: 8
      papers_read: 312
      keypoint_configs_tried: 5
      temporal_models_explored: 3
      
    pose_model_training:
      models_trained_this_week: 4
      gpu_hours: 1000
      best_pck: 0.923
      datasets: ["MPII", "COCO-Pose", "Leela-Motion-v2"]
      hands_still_tricky: true
      
    video_intake:
      streams_today: 47
      frames_processed: 1247000
      fork_efficiency: "99.2%"
      
    object_detection:
      objects_found: 3891247
      categories: 847
      confidence_avg: 0.94
      strangest_object: "A cat wearing a top hat"
      
    pose_estimation:
      poses_tracked: 891247
      gestures_recognized: 12400
      dances_identified: 3
      interpretive_dances: 1  # "We're still not sure"
      
    insight_generation:
      insights_created: 47891
      connections_found: 128947
      "aha_moments": 23
      
    python_actions:
      actions_defined: 156
      actions_triggered_today: 8472
      tables_emitting_to: 12
      avg_execution_time: "23ms"
      most_triggered: "MOTION_DETECTED"
      alerts_sent: 47
      state_machines_active: 8
      
    sql_storage:
      tables: 847
      rows: 28472910
      indices: 2847
      oldest_data: "2019-03-14"
      
    queries:
      queries_today: 4721
      avg_response_time: "47ms"
      slowest_query: "SELECT * FROM everything JOIN everything"
      
    visualizations:
      charts_generated: 847
      dashboards_active: 23
      "wow_reactions": 47
      
  methods:
    STATUS:
      description: "Check pipeline status"
      effect: "Display throughput at each stage"
      
    TRACE:
      description: "Follow data through the pipeline"
      parameters:
        video_id: "Source video identifier"
      effect: "Track from intake to visualization"
      
    EMERGENCY_STOP:
      description: "Halt all conveyors"
      effect: "*ALARM* â€” All lines stop. Data buffers."
      
    SUBMIT_VIDEO:
      description: "Add video to the pipeline"
      parameters:
        video: "Video stream or file"
      effect: "Forks to Objects and Poses tracks"
      
    ASK_PDA:
      description: "Have a PDA write a query for you"
      parameters:
        question: "Natural language question"
      effect: "PDA translates to SQL, runs query, returns results"
      
    VISUALIZE:
      description: "Generate visualization from query results"
      parameters:
        data: "Query results"
        style: "Chart type or 'auto'"
      effect: "Beautiful understanding emerges"
      
    DEFINE_ACTION:
      description: "Create a new Python action"
      parameters:
        name: "Action name (e.g., GREETING_DETECTED)"
        trigger: "Insight pattern to match"
        script: "Python code to execute"
        emit_to: "SQL tables to write to"
      effect: "New action registered in pipeline"
      
    LIST_ACTIONS:
      description: "Show all defined actions"
      effect: "Display action catalog with trigger patterns"
      
    TEST_ACTION:
      description: "Test action with sample insight"
      parameters:
        action: "Action name"
        insight: "Sample insight data"
      effect: "Dry run â€” shows what would be emitted"
      
    TRAIN_OBJECT_MODEL:
      description: "Submit object detection model for training"
      parameters:
        architecture: "Model architecture (YOLO, DETR, etc.)"
        dataset: "Training dataset"
        hyperparameters: "Training config"
      effect: "Model enters object training pipeline"
      
    TRAIN_POSE_MODEL:
      description: "Submit pose estimation model for training"
      parameters:
        architecture: "Model architecture (HRNet, ViTPose, etc.)"
        dataset: "Training dataset"
        hyperparameters: "Training config"
      effect: "Model enters pose training pipeline"
      
    DEPLOY_OBJECT_MODEL:
      description: "Deploy trained object model"
      parameters:
        model: "Model checkpoint"
      effect: "Hot-swap object detector in production"
      
    DEPLOY_POSE_MODEL:
      description: "Deploy trained pose model"
      parameters:
        model: "Model checkpoint"
      effect: "Hot-swap pose estimator in production"
      
    ROLLBACK_OBJECT:
      description: "Revert object detector to previous version"
      parameters:
        version: "Version to restore (default: previous)"
      effect: "Previous object model restored"
      
    ROLLBACK_POSE:
      description: "Revert pose estimator to previous version"
      parameters:
        version: "Version to restore (default: previous)"
      effect: "Previous pose model restored"
